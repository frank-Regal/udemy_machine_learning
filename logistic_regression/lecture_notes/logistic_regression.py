# -*- coding: utf-8 -*-
"""Logistic_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1npvZ6hHaa4Bqw059lHiCoVcbQGkoGiBV

**LOGISTIC REGRESSION**
"""

#Logistic regression
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn import datasets  #sklearn provides datasets

d = datasets.load_iris()

list(d.keys())  #what are the keys in this dataset, what we can do with it. The following are the list of dataset

d['data']  #It shows the iris data

d['target']  #It shows the target

''' #We have been given four features;
sepal lenght
sepal width
petal lenght
petal width
to predict them in these 3 labels (classes) in the form of 0s and 1s
iris setosa
iris versicolour
iris verginica

'''

print(d['DESCR'])  #It stands for description, it gives information about the data and its target like 0s and 1s.

d['data'].shape  #It gives the shape of the data, where we have 150 rows and 4 columns

d['data']

#Just for paractice I am gonna take only one feature and will train only one logistic classifier
# Now to store data and the target in one variable
#Note: We took only the third column from the above 'data'
x = d['data'][:,3:]  #I only need the fourth column and all the rows, so the data with the fourth column is stored in x
x

y = d['target'] #It gives the label(target) stored in y
y

#Train the logistic classifier to predict that whether the iris verginica is a follower or not.
''' We make it equal to 2, which means that if y equals to 2, it gives True, otherwise False. Why we make it equal to 2, we need to make
a classifier which will predict that whether iris verginica is a flower or not with the ouput either True or False.
The label will be equal to 2 which will return True or if it is not equal to 2, it will return False.
-But look we need the output in binary form; either 0 or 1. To do so we add astype(np.int). Because logistic regression dosn't understand
True, False. It understands integers, therefore we need to give y(target) in integer form, so we have np.int. It will enable  
the expression where it will return 1 if it is True and 0 if it is False.
'''
x = d['data'][:,3:]  #Data slicing
y = (d['target'] == 2).astype(np.int)   #y is the array of 0s and 1s
#To train a logistic regression classifier
model = LogisticRegression()  #Initial the logistic regression model, this is my model
#Now to fit x y. The classifier will read the data and will fit the x and y
model.fit(x,y) # It fits the values of x and y. We fit the classifier here
#Now to do prediction
prediction = model.predict(([[1.6]]))  #If we put the petal width  = 1.6. Do predict if it's true or false in binary form
prediction  #Classifier returns '0' means that it's False

prediction = model.predict(([[2]]))  #If we put the petal width  = 2. Do predict if it's true or false in binary form
prediction  #Classifier returns '1'. which means that it is True. it comes in 2 range.

#Now to visualize the classifier using matplotlib
x_new = np.linspace(0,3,1000).reshape(-1,1) #Initialized a new variable x_new. We need 1000 points between 0 and 3
#We reshape the numpy array with in the range of -1 to 1.
x_new  #It returns one dimensional array.

'''  predict_proba means to predic probability;
As we know that probability was telling us whether it is 0 or 1 with 0.5 threshold if it is verginica follower or not
''' 
y_probability = model.predict_proba(x_new) 
plt.plot(x_new,y_probability[:,1],"g-", label ='virginca' ) 
plt.show()
#So it has returned perfect logistic model in S shape within 0 and 3 linespace